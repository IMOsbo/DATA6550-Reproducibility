{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Hoehn/metrics-50000-Epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_perplexity</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>len_train_ds</th>\n",
       "      <th>len_val_ds</th>\n",
       "      <th>batches_per_epoch</th>\n",
       "      <th>time_per_epoch</th>\n",
       "      <th>fwd_time_in_epoch</th>\n",
       "      <th>epoch</th>\n",
       "      <th>...</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.self_attn.Wo.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.self_attn_norm.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.self_attn_norm.bias</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn.ffn.0.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn.ffn.2.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn_norm.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn_norm.bias</th>\n",
       "      <th>paramnorm_transformer.linear.weight</th>\n",
       "      <th>full_train_loss</th>\n",
       "      <th>full_train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.419975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.873535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.065536</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051147</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>0.025460</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>5.017161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.151625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.711868</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.119903</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051152</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.051143</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.051157</td>\n",
       "      <td>4.201431</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.425521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.556320</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.119197</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49995</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49996</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49997</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49998</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50425</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50426 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_loss  train_accuracy  train_perplexity  learning_rate  \\\n",
       "0        5.419975             0.0        225.873535         0.0000   \n",
       "1             NaN             NaN               NaN            NaN   \n",
       "2        5.151625             0.0        172.711868         0.0002   \n",
       "3             NaN             NaN               NaN            NaN   \n",
       "4        4.425521             0.0         83.556320         0.0004   \n",
       "...           ...             ...               ...            ...   \n",
       "50421    0.000000           100.0          1.000000         0.0010   \n",
       "50422    0.000000           100.0          1.000000         0.0010   \n",
       "50423    0.000000           100.0          1.000000         0.0010   \n",
       "50424    0.000000           100.0          1.000000         0.0010   \n",
       "50425    0.000000           100.0          1.000000         0.0010   \n",
       "\n",
       "       len_train_ds  len_val_ds  batches_per_epoch  time_per_epoch  \\\n",
       "0             470.0      8939.0                2.0        0.065536   \n",
       "1               NaN         NaN                NaN             NaN   \n",
       "2             470.0      8939.0                2.0        0.119903   \n",
       "3               NaN         NaN                NaN             NaN   \n",
       "4             470.0      8939.0                2.0        0.119197   \n",
       "...             ...         ...                ...             ...   \n",
       "50421         470.0      8939.0                2.0        0.047064   \n",
       "50422         470.0      8939.0                2.0        0.047064   \n",
       "50423         470.0      8939.0                2.0        0.047064   \n",
       "50424         470.0      8939.0                2.0        0.047064   \n",
       "50425         470.0      8939.0                2.0        0.047064   \n",
       "\n",
       "       fwd_time_in_epoch  epoch  ...  \\\n",
       "0               0.008008      0  ...   \n",
       "1                    NaN      1  ...   \n",
       "2               0.006053      1  ...   \n",
       "3                    NaN      2  ...   \n",
       "4               0.006120      2  ...   \n",
       "...                  ...    ...  ...   \n",
       "50421           0.006277  49995  ...   \n",
       "50422           0.006277  49996  ...   \n",
       "50423           0.006277  49997  ...   \n",
       "50424           0.006277  49998  ...   \n",
       "50425           0.006277  49999  ...   \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.self_attn.Wo.weight  \\\n",
       "0                                                    NaN            \n",
       "1                                               0.051147            \n",
       "2                                                    NaN            \n",
       "3                                               0.051152            \n",
       "4                                                    NaN            \n",
       "...                                                  ...            \n",
       "50421                                                NaN            \n",
       "50422                                                NaN            \n",
       "50423                                                NaN            \n",
       "50424                                                NaN            \n",
       "50425                                                NaN            \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.self_attn_norm.weight  \\\n",
       "0                                                    NaN              \n",
       "1                                               0.999960              \n",
       "2                                                    NaN              \n",
       "3                                               0.999854              \n",
       "4                                                    NaN              \n",
       "...                                                  ...              \n",
       "50421                                                NaN              \n",
       "50422                                                NaN              \n",
       "50423                                                NaN              \n",
       "50424                                                NaN              \n",
       "50425                                                NaN              \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.self_attn_norm.bias  \\\n",
       "0                                                    NaN            \n",
       "1                                               0.000295            \n",
       "2                                                    NaN            \n",
       "3                                               0.000978            \n",
       "4                                                    NaN            \n",
       "...                                                  ...            \n",
       "50421                                                NaN            \n",
       "50422                                                NaN            \n",
       "50423                                                NaN            \n",
       "50424                                                NaN            \n",
       "50425                                                NaN            \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn.ffn.0.weight  \\\n",
       "0                                                    NaN         \n",
       "1                                               0.051132         \n",
       "2                                                    NaN         \n",
       "3                                               0.051143         \n",
       "4                                                    NaN         \n",
       "...                                                  ...         \n",
       "50421                                                NaN         \n",
       "50422                                                NaN         \n",
       "50423                                                NaN         \n",
       "50424                                                NaN         \n",
       "50425                                                NaN         \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn.ffn.2.weight  \\\n",
       "0                                                    NaN         \n",
       "1                                               0.025460         \n",
       "2                                                    NaN         \n",
       "3                                               0.025474         \n",
       "4                                                    NaN         \n",
       "...                                                  ...         \n",
       "50421                                                NaN         \n",
       "50422                                                NaN         \n",
       "50423                                                NaN         \n",
       "50424                                                NaN         \n",
       "50425                                                NaN         \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn_norm.weight  \\\n",
       "0                                                    NaN        \n",
       "1                                               0.999965        \n",
       "2                                                    NaN        \n",
       "3                                               0.999967        \n",
       "4                                                    NaN        \n",
       "...                                                  ...        \n",
       "50421                                                NaN        \n",
       "50422                                                NaN        \n",
       "50423                                                NaN        \n",
       "50424                                                NaN        \n",
       "50425                                                NaN        \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn_norm.bias  \\\n",
       "0                                                    NaN      \n",
       "1                                               0.000294      \n",
       "2                                                    NaN      \n",
       "3                                               0.000974      \n",
       "4                                                    NaN      \n",
       "...                                                  ...      \n",
       "50421                                                NaN      \n",
       "50422                                                NaN      \n",
       "50423                                                NaN      \n",
       "50424                                                NaN      \n",
       "50425                                                NaN      \n",
       "\n",
       "       paramnorm_transformer.linear.weight  full_train_loss  full_train_acc  \n",
       "0                                      NaN              NaN             NaN  \n",
       "1                                 0.051170         5.017161             0.0  \n",
       "2                                      NaN              NaN             NaN  \n",
       "3                                 0.051157         4.201431             0.0  \n",
       "4                                      NaN              NaN             NaN  \n",
       "...                                    ...              ...             ...  \n",
       "50421                                  NaN              NaN             NaN  \n",
       "50422                                  NaN              NaN             NaN  \n",
       "50423                                  NaN              NaN             NaN  \n",
       "50424                                  NaN              NaN             NaN  \n",
       "50425                                  NaN              NaN             NaN  \n",
       "\n",
       "[50426 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"train_loss\", \"train_accuracy\"]] = data[[\"train_loss\", \"train_accuracy\"]].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData = data[data[\"val_loss\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_perplexity</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>len_train_ds</th>\n",
       "      <th>len_val_ds</th>\n",
       "      <th>batches_per_epoch</th>\n",
       "      <th>time_per_epoch</th>\n",
       "      <th>fwd_time_in_epoch</th>\n",
       "      <th>epoch</th>\n",
       "      <th>...</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.self_attn.Wo.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.self_attn_norm.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.self_attn_norm.bias</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn.ffn.0.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn.ffn.2.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn_norm.weight</th>\n",
       "      <th>paramnorm_transformer.decoder.blocks.1.ffn_norm.bias</th>\n",
       "      <th>paramnorm_transformer.linear.weight</th>\n",
       "      <th>full_train_loss</th>\n",
       "      <th>full_train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.419975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.873535</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.065536</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.419975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051147</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>0.025460</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.051170</td>\n",
       "      <td>5.017161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.151625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.711868</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.119903</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.151625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051152</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.051143</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.051157</td>\n",
       "      <td>4.201431</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.425521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.556320</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.119197</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50421</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49995</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50422</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49996</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50423</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49997</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50424</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49998</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50425</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>470.0</td>\n",
       "      <td>8939.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>49999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50426 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_loss  train_accuracy  train_perplexity  learning_rate  \\\n",
       "0        5.419975             0.0        225.873535         0.0000   \n",
       "1        5.419975             0.0               NaN            NaN   \n",
       "2        5.151625             0.0        172.711868         0.0002   \n",
       "3        5.151625             0.0               NaN            NaN   \n",
       "4        4.425521             0.0         83.556320         0.0004   \n",
       "...           ...             ...               ...            ...   \n",
       "50421    0.000000           100.0          1.000000         0.0010   \n",
       "50422    0.000000           100.0          1.000000         0.0010   \n",
       "50423    0.000000           100.0          1.000000         0.0010   \n",
       "50424    0.000000           100.0          1.000000         0.0010   \n",
       "50425    0.000000           100.0          1.000000         0.0010   \n",
       "\n",
       "       len_train_ds  len_val_ds  batches_per_epoch  time_per_epoch  \\\n",
       "0             470.0      8939.0                2.0        0.065536   \n",
       "1               NaN         NaN                NaN             NaN   \n",
       "2             470.0      8939.0                2.0        0.119903   \n",
       "3               NaN         NaN                NaN             NaN   \n",
       "4             470.0      8939.0                2.0        0.119197   \n",
       "...             ...         ...                ...             ...   \n",
       "50421         470.0      8939.0                2.0        0.047064   \n",
       "50422         470.0      8939.0                2.0        0.047064   \n",
       "50423         470.0      8939.0                2.0        0.047064   \n",
       "50424         470.0      8939.0                2.0        0.047064   \n",
       "50425         470.0      8939.0                2.0        0.047064   \n",
       "\n",
       "       fwd_time_in_epoch  epoch  ...  \\\n",
       "0               0.008008      0  ...   \n",
       "1                    NaN      1  ...   \n",
       "2               0.006053      1  ...   \n",
       "3                    NaN      2  ...   \n",
       "4               0.006120      2  ...   \n",
       "...                  ...    ...  ...   \n",
       "50421           0.006277  49995  ...   \n",
       "50422           0.006277  49996  ...   \n",
       "50423           0.006277  49997  ...   \n",
       "50424           0.006277  49998  ...   \n",
       "50425           0.006277  49999  ...   \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.self_attn.Wo.weight  \\\n",
       "0                                                    NaN            \n",
       "1                                               0.051147            \n",
       "2                                                    NaN            \n",
       "3                                               0.051152            \n",
       "4                                                    NaN            \n",
       "...                                                  ...            \n",
       "50421                                                NaN            \n",
       "50422                                                NaN            \n",
       "50423                                                NaN            \n",
       "50424                                                NaN            \n",
       "50425                                                NaN            \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.self_attn_norm.weight  \\\n",
       "0                                                    NaN              \n",
       "1                                               0.999960              \n",
       "2                                                    NaN              \n",
       "3                                               0.999854              \n",
       "4                                                    NaN              \n",
       "...                                                  ...              \n",
       "50421                                                NaN              \n",
       "50422                                                NaN              \n",
       "50423                                                NaN              \n",
       "50424                                                NaN              \n",
       "50425                                                NaN              \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.self_attn_norm.bias  \\\n",
       "0                                                    NaN            \n",
       "1                                               0.000295            \n",
       "2                                                    NaN            \n",
       "3                                               0.000978            \n",
       "4                                                    NaN            \n",
       "...                                                  ...            \n",
       "50421                                                NaN            \n",
       "50422                                                NaN            \n",
       "50423                                                NaN            \n",
       "50424                                                NaN            \n",
       "50425                                                NaN            \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn.ffn.0.weight  \\\n",
       "0                                                    NaN         \n",
       "1                                               0.051132         \n",
       "2                                                    NaN         \n",
       "3                                               0.051143         \n",
       "4                                                    NaN         \n",
       "...                                                  ...         \n",
       "50421                                                NaN         \n",
       "50422                                                NaN         \n",
       "50423                                                NaN         \n",
       "50424                                                NaN         \n",
       "50425                                                NaN         \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn.ffn.2.weight  \\\n",
       "0                                                    NaN         \n",
       "1                                               0.025460         \n",
       "2                                                    NaN         \n",
       "3                                               0.025474         \n",
       "4                                                    NaN         \n",
       "...                                                  ...         \n",
       "50421                                                NaN         \n",
       "50422                                                NaN         \n",
       "50423                                                NaN         \n",
       "50424                                                NaN         \n",
       "50425                                                NaN         \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn_norm.weight  \\\n",
       "0                                                    NaN        \n",
       "1                                               0.999965        \n",
       "2                                                    NaN        \n",
       "3                                               0.999967        \n",
       "4                                                    NaN        \n",
       "...                                                  ...        \n",
       "50421                                                NaN        \n",
       "50422                                                NaN        \n",
       "50423                                                NaN        \n",
       "50424                                                NaN        \n",
       "50425                                                NaN        \n",
       "\n",
       "       paramnorm_transformer.decoder.blocks.1.ffn_norm.bias  \\\n",
       "0                                                    NaN      \n",
       "1                                               0.000294      \n",
       "2                                                    NaN      \n",
       "3                                               0.000974      \n",
       "4                                                    NaN      \n",
       "...                                                  ...      \n",
       "50421                                                NaN      \n",
       "50422                                                NaN      \n",
       "50423                                                NaN      \n",
       "50424                                                NaN      \n",
       "50425                                                NaN      \n",
       "\n",
       "       paramnorm_transformer.linear.weight  full_train_loss  full_train_acc  \n",
       "0                                      NaN              NaN             NaN  \n",
       "1                                 0.051170         5.017161             0.0  \n",
       "2                                      NaN              NaN             NaN  \n",
       "3                                 0.051157         4.201431             0.0  \n",
       "4                                      NaN              NaN             NaN  \n",
       "...                                    ...              ...             ...  \n",
       "50421                                  NaN              NaN             NaN  \n",
       "50422                                  NaN              NaN             NaN  \n",
       "50423                                  NaN              NaN             NaN  \n",
       "50424                                  NaN              NaN             NaN  \n",
       "50425                                  NaN              NaN             NaN  \n",
       "\n",
       "[50426 rows x 56 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_loss',\n",
       " 'train_accuracy',\n",
       " 'train_perplexity',\n",
       " 'learning_rate',\n",
       " 'len_train_ds',\n",
       " 'len_val_ds',\n",
       " 'batches_per_epoch',\n",
       " 'time_per_epoch',\n",
       " 'fwd_time_in_epoch',\n",
       " 'epoch',\n",
       " 'step',\n",
       " 'val_loss',\n",
       " 'val_accuracy',\n",
       " 'val_perplexity',\n",
       " 'paramnorm_transformer.embedding.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.0.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.0.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.0.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.1.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.1.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.1.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.2.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.2.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.2.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.3.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.3.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.attn_heads.3.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn.Wo.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn_norm.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.self_attn_norm.bias',\n",
       " 'paramnorm_transformer.decoder.blocks.0.ffn.ffn.0.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.ffn.ffn.2.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.ffn_norm.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.0.ffn_norm.bias',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.0.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.0.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.0.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.1.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.1.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.1.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.2.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.2.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.2.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.3.Wq.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.3.Wk.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.attn_heads.3.Wv.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn.Wo.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn_norm.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.self_attn_norm.bias',\n",
       " 'paramnorm_transformer.decoder.blocks.1.ffn.ffn.0.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.ffn.ffn.2.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.ffn_norm.weight',\n",
       " 'paramnorm_transformer.decoder.blocks.1.ffn_norm.bias',\n",
       " 'paramnorm_transformer.linear.weight',\n",
       " 'full_train_loss',\n",
       " 'full_train_acc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='epoch', ylabel='val_accuracy'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=filteredData, x=\"epoch\", y=\"val_accuracy\")\n",
    "sns.lineplot(data=filteredData, x=\"epoch\", y=\"train_accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
